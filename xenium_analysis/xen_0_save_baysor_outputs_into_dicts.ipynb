{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfe92e-9b3e-43f3-8e08-3bafbbd82f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import squidpy as sq\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import imagecodecs\n",
    "import tifffile as tff\n",
    "from pyometiff import OMETIFFReader\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import norm\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import umap\n",
    "import anndata as ad\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', \n",
    "                    datefmt='%d-%b-%y %H:%M:%S',\n",
    "                    handlers=[logging.StreamHandler(),\n",
    "                                logging.FileHandler(\"test.log\", \"a\")])\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "from itables import init_notebook_mode\n",
    "init_notebook_mode(all_interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73333c9c-1db0-44c0-ac2d-4efbeb97e42e",
   "metadata": {},
   "source": [
    "# Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28de2f-8ae3-41cf-afc4-0f7d36909bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup function for calculating elapsed time\n",
    "def print_elapsed_time(start,stop):\n",
    "    # Calculate the elapsed time in seconds\n",
    "    elapsed_seconds=stop-start\n",
    "    \n",
    "    # Convert elapsed time to hours and minutes\n",
    "    elapsed_minutes, elapsed_seconds = divmod(int(elapsed_seconds), 60)\n",
    "    elapsed_hours, elapsed_minutes = divmod(elapsed_minutes, 60)\n",
    "    \n",
    "    # Print the result in the desired format\n",
    "    return(f\"{elapsed_hours} hours: {elapsed_minutes} minutes: {elapsed_seconds} seconds\") \n",
    "\n",
    "\n",
    "### =================================================================\n",
    "## Read nucleus/cell boundary .csv files + cell summary .csv\n",
    "def read_boundary_files(data_dir,sample_dir):\n",
    "    nucleus_bound=pd.read_csv(os.path.join(data_dir,sample_dir,'nucleus_boundaries.csv.gz'))\n",
    "    cell_bound=pd.read_csv(os.path.join(data_dir,sample_dir,'cell_boundaries.csv.gz'))\n",
    "    #transcripts=pd.read_csv(os.path.join(data_dir,sample_dir,'transcripts.csv.gz'))    \n",
    "    #cells=pd.read_csv(os.path.join(data_dir,sample_dir,'cells.csv.gz'))\n",
    "\n",
    "    return nucleus_bound,cell_bound\n",
    "\n",
    "\n",
    "### =================================================================\n",
    "## Read __morphology_focus.ome.tiff__ DAPI-fluorescence picture of slide\n",
    "def read_ome_tiff(slide_type,data_dir,sample_dir):\n",
    "    if slide_type=='focus':\n",
    "        fn=os.path.join(data_dir,sample_dir,'morphology_focus.ome.tif')\n",
    "\n",
    "    if slide_type=='mip':    \n",
    "        fn=os.path.join(data_dir,sample_dir,'morphology_mip.ome.tif')\n",
    "\n",
    "    if slide_type=='z_stack': \n",
    "        fn=os.path.join(data_dir,sample_dir,'morphology.ome.tif')\n",
    "        \n",
    "    reader = OMETIFFReader(fpath=fn)\n",
    "    img_array,metadata,xml_metadata=reader.read()\n",
    "\n",
    "    return img_array,metadata,xml_metadata\n",
    "\n",
    "\n",
    "\n",
    "### =================================================================\n",
    "\n",
    "## Create dataframe of mask polygon coordinates from json outputs, that Baysor created\n",
    "def create_cell_bound_df(polygon_fn,seg):\n",
    "\n",
    "    ## The cell names in segmentation.csv have a prefix in front of the cell name (i.e.'CRe50034e63-1')\n",
    "    #  Extract that prefix and add it to the cell names coming from the json file to make them uniform\n",
    "    prefix=seg.loc[~seg['cell'].isna(),'cell'].str.split('-',expand=True)[0].unique()\n",
    "\n",
    "    if len(prefix)!=1:\n",
    "        raise ValueError('Multiple prefixes in the segmentation.csv cell column => check the length of prefix variable in create_polygon_df() function!')\n",
    "\n",
    "    prefix=prefix[0]\n",
    "    \n",
    "    import json\n",
    "    # Opening JSON file\n",
    "    f=open(polygon_fn)\n",
    "    polygon=json.load(f)\n",
    "    \n",
    "    ## Init list to collect cell dfs with coordinates\n",
    "    df_list=[]\n",
    "    for n in range(len(polygon['geometries'])):\n",
    "        ## Extract polygon coordinates\n",
    "        coord=np.squeeze(np.array(polygon['geometries'][n]['coordinates']))\n",
    "        \n",
    "        ## Add only cells with non-empty masks\n",
    "        if (coord.shape[0])>0:\n",
    "\n",
    "            ## Extract cell name\n",
    "            cell_name=polygon['geometries'][n]['cell']\n",
    "            cell_name_arr=np.array([cell_name,]*int(coord.shape[0]))\n",
    "\n",
    "            ## Stack coordinates and cell_name and create dataframe\n",
    "            coord_with_name=np.hstack((coord,cell_name_arr.reshape(-1, 1)))\n",
    "            colnames=['vertex_x_pixel','vertex_y_pixel','cell_id']\n",
    "            df=pd.DataFrame(data=coord_with_name,columns=colnames)\n",
    "        \n",
    "            ## If cell name doesn't start with prefix (most of the time it doesn't, sometimes it does as it was saved with the prefix in the json file),\n",
    "            #  add prefix\n",
    "\n",
    "            #if not str(cell_name).startswith(prefix):\n",
    "            df['cell_id']=prefix + '-' + df['cell_id'].astype(int).astype(str)\n",
    "            df_list.append(df)\n",
    "\n",
    "    ## Concatenate all cell dfs into one\n",
    "    df=pd.concat(df_list)    \n",
    "\n",
    "    return df    \n",
    "\n",
    "\n",
    "### =================================================================\n",
    "\n",
    "## Calculate nucleus pixel metric: median/mean/max/mode of nucleus pixels\n",
    "def return_polygon_pixel_metric(x,img_array,metric):\n",
    "    from matplotlib import path\n",
    "    import statistics as st\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "       \n",
    "    ## Extract the vertex points of nucleus polygon + boundaries of \n",
    "    polygon_vert=list(zip(x['vertex_x_pixel'],x['vertex_y_pixel']))\n",
    "\n",
    "    ## Extract rectangle around nucleus -> get coordinates of nucleus polygon and create rectangle\n",
    "    x_min=int(x['vertex_x_pixel'].min())\n",
    "    x_max=int(x['vertex_x_pixel'].max())\n",
    "\n",
    "    y_min=int(x['vertex_y_pixel'].min())\n",
    "    y_max=int(x['vertex_y_pixel'].max())\n",
    "\n",
    "\n",
    "    ## Create rectangle around nucleus\n",
    "    nx,ny=x_max-x_min+1,y_max-y_min+1\n",
    "    x_,y_=np.meshgrid(np.arange(nx), np.arange(ny))\n",
    "    x__,y__=x_.flatten()+x_min, y_.flatten()+y_min\n",
    "\n",
    "    points = np.vstack((x__,y__)).T\n",
    "\n",
    "    ## Check if created rectangle's pixels are inside/outside of polygon -> \n",
    "    #  mask_: boolean mask; False: pixel outside of nucl. polygon; True: pixel inside of nucl. polygon)\n",
    "    p=path.Path(polygon_vert)\n",
    "    mask=p.contains_points(points)\n",
    "    mask_=mask.reshape(ny,nx)\n",
    "\n",
    "\n",
    "\n",
    "    ## Extract the pixel numbers of the pixels from inside the polygon \n",
    "    #  Subset original image to rectangle around nucleus (saves memory)\n",
    "\n",
    "    ## Some polygons output by Baysor are outside of the image -> their coordinates are larger than the img_array's shape\n",
    "    #  => In this case just only take part of the polygons that lies on the image = resize mask_ to fit on img_array\n",
    "    y_max_coor=min(img_array.shape[0],y_min+ny)\n",
    "    x_max_coor=min(img_array.shape[1],x_min+nx)\n",
    "    sub_img_array=img_array[y_min:y_max_coor,x_min:x_max_coor]\n",
    "    mask_=mask_[0:y_max_coor-y_min,0:x_max_coor-x_min]\n",
    "\n",
    "    ## Calculate metric of nucleus pixels (rectangle masked with boolean mask)\n",
    "\n",
    "    def return_indentity(x):\n",
    "        return x\n",
    "    \n",
    "    metric_dict={'median':np.median,'mean':np.mean,'max':np.max,'mode':st.mode,'raw_vals':return_indentity}\n",
    "    metric_func=metric_dict[metric]\n",
    "\n",
    "\n",
    "    ## Check if there are at least 3 unique polygon vertices (for some points baysor outputs only 1 unique x-y pair)\n",
    "    try:\n",
    "        nucleus_polygon_metric=metric_func(sub_img_array[mask_].flatten())\n",
    "    except ValueError:\n",
    "         nucleus_polygon_metric=np.nan\n",
    "\n",
    "    '''\n",
    "    ## Plotting functions to showcase the pixels of the polygon for one nucleus\n",
    "    #  For this, run the following code outside of ths function:\n",
    "\n",
    "    #  cell_id='aaaejiml-1'\n",
    "    #  nucleus_bound[nucleus_bound['cell_id']==cell_id].groupby('cell_id').apply(return_polygon_pixels,img_array=img_array)\n",
    "\n",
    "    #print('mask_',mask_)\n",
    "    \n",
    "    ## Plot the nuclues boolean mask \n",
    "    fig,ax=plt.subplots(1,3,figsize=(8,5))\n",
    "    ax[0].imshow(mask_,origin='upper')\n",
    "\n",
    "    ## Plot the polygon with GeoPandas dataframe for given cell\n",
    "    #nucleus_polygons.loc[nucleus_polygons.index.isin(['aaaejiml-1']),:].plot(ax=ax[1],column='real_cell',cmap=reversed_map,legend=True,alpha=0.3)\n",
    "    #nucleus_polygons.loc[nucleus_polygons.index.isin(['aaakgmde-1']),:].plot(ax=ax[1],column='real_cell',cmap=reversed_map,legend=True,alpha=0.3)\n",
    "    #ax[1].invert_yaxis()\n",
    "\n",
    "    ## Show raw nucleus data taken from oiriginal image\n",
    "    #  Subset original slide image to a rectangle around the nucleus \n",
    "    sub_img_array=img_array[y_min:y_min+ny,x_min:x_min+nx]\n",
    "    img=ax[1].imshow(points,origin='upper')\n",
    "\n",
    "    ## Show nucleus masked with polygon + DAPI intensities inside of polygon\n",
    "    #sub_img_array[~mask_]=0\n",
    "    img2=ax[2].imshow(sub_img_array,origin='upper')\n",
    "    #plt.colorbar(img2, ax=ax[2])\n",
    "    plt.show()\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    return nucleus_polygon_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47017ee0-6d54-4262-80f2-dc47b5a7c482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T13:39:37.424943Z",
     "iopub.status.busy": "2024-01-30T13:39:37.424405Z",
     "iopub.status.idle": "2024-01-30T13:39:37.428132Z",
     "shell.execute_reply": "2024-01-30T13:39:37.427574Z",
     "shell.execute_reply.started": "2024-01-30T13:39:37.424923Z"
    }
   },
   "source": [
    "# Save baysor segmentation outputs in dicts RUNTIME ~ 4-5 hours\n",
    "- Cell boundaries\n",
    "- Segmentation statistics\n",
    "- Calculate intensity metrics of cellular masks (mean,median,mode,max) for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a08b01-6c66-40b6-bea4-7db9c8f30075",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"/data/gpfs/projects/punim2121/Atherosclerosis/xenium_data/\"#processed_data/cell_segmentation\"\n",
    "\n",
    "## Drop scratch folders that start with \"._\"\n",
    "panel_dir=[f for f in os.listdir(data_dir) if ('Panel' in f and '._' not in f)]\n",
    "panel_dir.sort()\n",
    "\n",
    "## Create list of samples to loop over (as script sometimes exits due to kernel death, this cell may need to be run split between the samples)\n",
    "#  => this list controls which samples are being processed\n",
    "panels=['Panel1','Panel2']\n",
    "samples=['P1_H','P2_H','P3_H','P4_H','P1_D','P2_D','P3_D','P4_D']\n",
    "\n",
    "#panels=['Panel1']\n",
    "#samples=['P3_D']\n",
    "samples_to_loop_over=['_'.join([panel,sample]) for panel in panels for sample in samples]\n",
    "\n",
    "segmend_dict={'no_segmentation':{},\n",
    "             '10x':{'expansion_sizes':[0]},\n",
    "             'cellpose':{'expansion_sizes':[4,6,10],\n",
    "                         'modes':['cyto','nucleus']}\n",
    "             }\n",
    "\n",
    "\n",
    "for panel in panel_dir[:]:\n",
    "    panel_dir=os.path.join(data_dir,panel)\n",
    " \n",
    "    ## Loop over all samples in a batch\n",
    "    for sample_name in os.listdir(panel_dir)[0:]:\n",
    "        sample_dir=os.path.join(data_dir,panel,sample_name)\n",
    "\n",
    "        if os.path.isdir(sample_dir): #and 'P1_D' in sample_dir:\n",
    "            sample_dict={}\n",
    "            \n",
    "            ## Extract Panel_Sample_name as string\n",
    "            panel_sample_name='_'.join([panel.split('_')[-1],sample_name.split('__')[2]])\n",
    "\n",
    "            ## Check if the sample name is in the samples that should be processed => if yes process them\n",
    "            if panel_sample_name in samples_to_loop_over:\n",
    "                logging.info(panel_sample_name)\n",
    "                \n",
    "    \n",
    "                ## Load DAPI fluorescent-stained slide image\n",
    "                # Select one slide_type ('mip'/'focus'/z_stack') file to load and \n",
    "                slide_type='mip'\n",
    "                img_array,metadata,xml_metadata=read_ome_tiff(slide_type,data_dir,sample_dir)\n",
    "                logging.info('Slide loaded')\n",
    "    \n",
    "                ## Create baysor output folder path\n",
    "                baysor_out_fold=os.path.join(data_dir,'processed_data/baysor_output',panel_sample_name)\n",
    "    \n",
    "                ## Get only name of folders to loop over in baysor_output folder (filter for segmentation methods as well)\n",
    "                bays_model_dirlist=[filename for filename in os.listdir(baysor_out_fold) if os.path.isdir(os.path.join(baysor_out_fold,filename))]\n",
    "                #bays_model_dirlist=[filename for filename in bays_model_dirlist if any(x in filename for x in \\\n",
    "                #                                                                       ['cellpose_baysor-CPn_0','cellpose_baysor-CPc_0'])] #'no_segmentation','10x',\n",
    "                \n",
    "                \n",
    "                ### Loop over baysor segmentation models and extract cell mask polygon metrics\n",
    "                for bays_model_name in bays_model_dirlist[:]:\n",
    "                    logging.info(bays_model_name)\n",
    "    \n",
    "                    ## Read in segmentation results + cell statistics output by Baysor (cells stats, area of cells)\n",
    "                    seg_fn=os.path.join(baysor_out_fold,bays_model_name,'segmentation.csv')\n",
    "                    seg=pd.read_csv(seg_fn)\n",
    "                 \n",
    "                    seg_stats_fn=os.path.join(baysor_out_fold,bays_model_name,'segmentation_cell_stats.csv')\n",
    "                    seg_stats=pd.read_csv(seg_stats_fn)\n",
    "    \n",
    "                    polygon_fn=os.path.join(baysor_out_fold,bays_model_name,'segmentation_polygons.json')\n",
    "                    cell_bound=create_cell_bound_df(polygon_fn,seg)\n",
    "    \n",
    "    \n",
    "                    ## Extract pixels of cell mask polygons (identified by Baysor model) and return a dataframe with some metrics of these pixel \n",
    "                    #  intensities\n",
    "                    metric_df_list=[]\n",
    "                    metric_list=['median','mean','max','mode','raw_vals']\n",
    "                    for metric in metric_list:\n",
    "                        temp_df=cell_bound.groupby('cell_id').apply(return_polygon_pixel_metric,img_array=img_array,metric=metric)\n",
    "                        metric_df_list.append(temp_df)                \n",
    "                    #del img_array               \n",
    "                    nucleus_polygon_pixel_metrics=pd.concat(metric_df_list,axis=1)\n",
    "                    nucleus_polygon_pixel_metrics.columns=metric_list\n",
    "                    logging.info('Cellular polygon metrics calculated')\n",
    "    \n",
    "                    \n",
    "                    ## Save the processed data as a dictionary\n",
    "                    #sample_dict['seg_stats']=seg_stats\n",
    "                    sample_dict['cell_bound']=cell_bound\n",
    "                    sample_dict['cell_polygon_pixel_metrics']=nucleus_polygon_pixel_metrics\n",
    "                    sample_dict['slide_metadata']=metadata\n",
    "                    \n",
    "                    proc_dir=os.path.join(data_dir,'processed_data/true_cell_filtering/baysor',panel_sample_name,bays_model_name)\n",
    "                    \n",
    "                    if not os.path.isdir(proc_dir):\n",
    "                        os.makedirs(proc_dir)\n",
    "                        logging.info(f'Created directory: {proc_dir}')\n",
    "    \n",
    "                    fpath=os.path.join(proc_dir,panel_sample_name+'.pickle')\n",
    "                    pickle.dump(sample_dict, open(fpath, \"wb\"))\n",
    "                    logging.info(f'{panel_sample_name}-{bays_model_name} saved as pickle\\n')\n",
    "                logging.info('=====================')\n",
    " \n",
    "logging.info('Done!')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium",
   "language": "python",
   "name": "xenium"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
