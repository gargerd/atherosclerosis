{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8179edf-8942-4e6f-9c82-a656199fbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc,anndata as ad\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "from anndata import AnnData\n",
    "os.chdir(os.getcwd())\n",
    "import scarches as sca\n",
    "from scarches.models.scpoli import scPoli\n",
    "\n",
    "import scvi\n",
    "import itertools\n",
    "import torch\n",
    "import time\n",
    "#import ray\n",
    "#from ray import tune\n",
    "#from scvi import autotune\n",
    "import pickle\n",
    "from itables import init_notebook_mode\n",
    "init_notebook_mode(all_interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c94990a-0f9f-4727-8954-72b473f89b6e",
   "metadata": {},
   "source": [
    "# Setup functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81af49a-8bb1-4866-9d24-80c852f6317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup function for calculating elapsed time\n",
    "def print_elapsed_time(start,stop):\n",
    "    # Calculate the elapsed time in seconds\n",
    "    elapsed_seconds = stop - start\n",
    "    \n",
    "    # Convert elapsed time to hours and minutes\n",
    "    elapsed_minutes, elapsed_seconds = divmod(int(elapsed_seconds), 60)\n",
    "    elapsed_hours, elapsed_minutes = divmod(elapsed_minutes, 60)\n",
    "    \n",
    "    # Print the result in the desired format\n",
    "    print(f\"Elapsed time:{elapsed_hours} hours:{elapsed_minutes} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e35ddd4-4fda-4730-b979-09c07863bcfa",
   "metadata": {},
   "source": [
    "# LOAD DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26263d7-15ee-4ed4-8b09-52e21e758c4b",
   "metadata": {},
   "source": [
    "## Load adata and Tabula Sapiens vascular + blood dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c24324b-3a3f-4a4f-8a5a-509dc105e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "adata_ts=sc.read_h5ad('../../data/ts_blood_vasc.h5ad')\n",
    "adata_ts.obs['scanvi_batch']=adata_ts.obs['donor'].astype(str) +'_'+ adata_ts.obs['method'].astype(str)\n",
    "adata_ts.obs['scanvi_batch']=adata_ts.obs['scanvi_batch'].astype('category')\n",
    "adata_ts.X=sparse.csr_matrix(adata_ts.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a2f56-b647-4333-8b45-6fee5a05f1c8",
   "metadata": {},
   "source": [
    "## Load preprocessed Xenium anndata files + subset TS data to common genes with Xenium panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c416826f-b67d-4dd7-9337-0642eff4a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_dir='/data/gpfs/projects/punim2121/Atherosclerosis/xenium_data/processed_data/baysor_processed_output'\n",
    "\n",
    "adata_dict={}\n",
    "adata_ts_dict={}\n",
    "adata_merged_dict={}\n",
    "for panel in ['Panel1','Panel2'][:]:\n",
    "    fn=os.path.join(proc_dir,f'filtered_{panel}_cells.h5ad')\n",
    "    adata=sc.read_h5ad(fn)\n",
    "\n",
    "\n",
    "    ## Add some columnms (originating from the reference TS data) to xenium data obs, which will be covariate keys in the scVI model\n",
    "    adata.obs['donor']=adata.obs['patient'].values\n",
    "    adata.obs['method']='xenium'\n",
    "    adata.obs['free_annotation']='unknown'\n",
    "    adata.obs['organ_tissue']='Vasculature'\n",
    "\n",
    "    for coln in ['free_annotation','donor','organ_tissue','method']:\n",
    "        adata.obs[coln]=adata.obs[coln].astype('category')\n",
    "        \n",
    "    \n",
    "\n",
    "    common_genes=list(set(adata_ts.var_names)&set(adata.var_names))\n",
    "    print(f'Number of common genes between TS and {panel} data: {len(common_genes)} out of {len(adata.var_names)}')\n",
    "    \n",
    "    adata_dict[panel]=adata[:,common_genes].copy()\n",
    "    adata_ts_dict[panel]=adata_ts[:,common_genes].copy()\n",
    "\n",
    "    adata_merged_dict[panel]=ad.concat([adata_ts[:,common_genes].copy(),adata[:,common_genes].copy()],\n",
    "                                       label='dataset_origin',keys=['TS','xenium'],join='outer',merge='unique')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1819e6-731c-4566-8085-ae74941b55de",
   "metadata": {},
   "source": [
    "## SCPOLI TRAINING ON REFERENCE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708d9ef-d95c-4f65-8ad8-be76d639ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###====== DEFINE TRAINIG KWARGS\n",
    "train_kwargs = {\n",
    "    \"early_stopping\": True,\n",
    "    \"early_stopping_monitor\": \"elbo_validation\",\n",
    "    \"early_stopping_patience\": 30,\n",
    "    \"early_stopping_min_delta\": 0.00001,\n",
    "    \"check_val_every_n_epoch\":1,\n",
    "    \"plan_kwargs\": {\"weight_decay\": 1e-6},\n",
    "    'accelerator':'auto'}\n",
    "\n",
    "\n",
    "###====== DEFINE HYPERPARAMETERS FOR MODELS TO TRAIN\n",
    "search_space={\n",
    "        \"n_hidden\":[128],\n",
    "        \"n_latent\":[10],\n",
    "        \"n_layers\": [1],\n",
    "        'gene_likelihood':['nb']}\n",
    "\n",
    "# Create a list of dictionaries where each dictionary represents a set of hyperparameters\n",
    "parameter_combinations = list(itertools.product(*search_space.values()))\n",
    "hyperparameter_sets = [{key: value for key, value in zip(search_space.keys(), combination)} for combination in parameter_combinations]\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "###====== RUN TRAINING\n",
    "## Concatenate the 2 batch effect columns into one, as scNVI can only handle one batch effect covariate\n",
    "for panel in ['Panel1','Panel2']:\n",
    "    print(panel)\n",
    "    adata_ts_panel=adata_ts_dict[panel]\n",
    "\n",
    "    adata_ts_panel.obs['scanvi_batch']=adata_ts_panel.obs['donor'].astype(str) +'_'+ adata_ts_panel.obs['method'].astype(str)\n",
    "    adata_ts_panel.obs['scanvi_batch']=adata_ts_panel.obs['scanvi_batch'].astype('category')\n",
    "    adata_ts_panel.obs['donor']=adata_ts_panel.obs['donor'].astype('category')\n",
    "    #adata_ts_panel=adata_ts_panel.copy()\n",
    "\n",
    "\n",
    "    adata_merged=adata_merged_dict[panel]\n",
    "\n",
    "    for n,hyperparameters in enumerate(hyperparameter_sets):\n",
    "        loop_time=time.time()\n",
    "    \n",
    "        print_elapsed_time(start,loop_time)\n",
    "        print('set:',str(n+1),'/',str(len(hyperparameter_sets))) \n",
    "        print(hyperparameters)\n",
    "        \n",
    "        ## Create string of the parameters\n",
    "        pairs=[f\"{key}:{value}\" for key, value in hyperparameters.items()]\n",
    "        param_set_string='-'.join(pairs)\n",
    "    \n",
    "        \n",
    "        ## Setup model    \n",
    "        sca.models.SCVI.setup_anndata(adata_merged,\n",
    "                                     layer=\"raw_counts\",\n",
    "                                     categorical_covariate_keys=['donor'],\n",
    "                                     batch_key='method',\n",
    "                                     labels_key='free_annotation')\n",
    "        \n",
    "        vae=sca.models.SCVI(adata_merged,\n",
    "                            n_layers=hyperparameters['n_layers'],\n",
    "                            n_hidden=hyperparameters['n_hidden'],\n",
    "                            n_latent=hyperparameters['n_latent'],\n",
    "                            gene_likelihood=hyperparameters['gene_likelihood']\n",
    "                            )\n",
    "    \n",
    "    \n",
    "        vae.train(max_epochs=500,**train_kwargs)\n",
    "    \n",
    "        ## Plot training results\n",
    "        fig,ax=plt.subplots(1,2,figsize=(9,3))\n",
    "        fig.suptitle('-'.join([panel,param_set_string]))\n",
    "        d=vae.history\n",
    "        ax[0].plot(d['reconstruction_loss_train']['reconstruction_loss_train'], label='reconstruction_loss_train')\n",
    "        ax[0].plot(d['reconstruction_loss_validation']['reconstruction_loss_validation'], label='reconstruction_loss_validation')\n",
    "        ax[1].plot(d['elbo_validation']['elbo_validation'], label='elbo_validation')\n",
    "        ax[1].plot(d['elbo_train']['elbo_train'], label='elbo_train')    \n",
    "        ax[0].legend()\n",
    "        ax[1].legend()\n",
    "    \n",
    "        ## Create string from parameters==> add to the name of the model when saving\n",
    "        pairs=[f\"{key}:{value}\" for key, value in hyperparameters.items()]\n",
    "        param_set_string='-'.join(pairs)\n",
    "        \n",
    "        ## Save model\n",
    "        path=os.path.join(proc_dir,\"scvi_models\",panel+\"_ts_model_\"+param_set_string)\n",
    "        os.makedirs(path, exist_ok=True) \n",
    "        vae.save(path,overwrite=True)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
