{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b60e2-0cd5-4f2a-ad0f-d6fbe1b52656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scarches as sca\n",
    "#import torch\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3551af74-5138-40c4-a6f8-b6eea923f329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Setup function for calculating elapsed time\n",
    "def print_elapsed_time(start,stop):\n",
    "    # Calculate the elapsed time in seconds\n",
    "    elapsed_seconds = stop - start\n",
    "    \n",
    "    # Convert elapsed time to hours and minutes\n",
    "    elapsed_minutes, elapsed_seconds = divmod(int(elapsed_seconds), 60)\n",
    "    elapsed_hours, elapsed_minutes = divmod(elapsed_minutes, 60)\n",
    "    \n",
    "    # Print the result in the desired format\n",
    "    print(f\"Elapsed time:{elapsed_hours} hours:{elapsed_minutes} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8368e4-6dec-4b35-a3de-d33997b3cf4a",
   "metadata": {},
   "source": [
    "# LOAD DATA & SUBSET TO PATIENTS 1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0f88d-498d-4619-ba1d-63eaf1892a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "proc_dir='/data/gpfs/projects/punim2121/Atherosclerosis/xenium_data/processed_data/baysor_processed_output'\n",
    "scale_param='10'#'5'#'5|10|15'\n",
    "avg_assignment_conf_thr=0.75\n",
    "\n",
    "adata_dict={}\n",
    "for panel in ['Panel1','Panel2'][:]:\n",
    "\n",
    "    fn=os.path.join(proc_dir,f'filtered_{panel}_cells_scale_{scale_param}_asg_conf_{avg_assignment_conf_thr}.h5ad')\n",
    "    adata=sc.read_h5ad(fn)\n",
    "    \n",
    "    adata=adata[adata.obs['patient'].isin(['P1','P2','P3','P4']),:].copy()\n",
    "    print(adata.shape)\n",
    "    adata_dict[panel]=adata.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549ccacc-5ab8-4e87-b66a-a087e8c6db85",
   "metadata": {},
   "source": [
    "# Add ENSEMBL IDs of gene names to adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2cade2-4d50-449c-a502-4d2c83c318e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## THE EXACT ENSEMBL IDS -HGNCE NAME PAIRS ARE STORED IN THE GENE_PANEL.JSON FILES (THE SAME FOR ALL SAMPLES WITHIN RESPECTIVE GENE PANEL)\n",
    "#  ==> EXTRACT THE ENSEMBL IDS;HGNC NAME PAIRS AND ADD THEM TO ADATA.VAR, TO MAKE SURE UNIQUE GENE NAMES ARE USED\n",
    "def extract_ensembl_hgnc_name_df():\n",
    "    \n",
    "    panel_sample_dirs=[\"20230808__140639__2311_Sachs_Panel1/output-XETG00050__0003370__P3_D__20230808__140759\",\n",
    "                       \"20230817__135824__2311_Sachs_Panel2/output-XETG00050__0003341__P3_D__20230817__135943\"]\n",
    "    data_dir=\"/data/gpfs/projects/punim2121/Atherosclerosis/xenium_data/\"\n",
    "    import json\n",
    "    \n",
    "    df_list=[]\n",
    "    for panel,sample_dir in zip(['Panel1','Panel2'],panel_sample_dirs):\n",
    "   \n",
    "        with open(os.path.join(data_dir,sample_dir,'gene_panel.json')) as f:\n",
    "            gene_panel=json.load(f)\n",
    "        \n",
    "        ensembl_id_list,hgnc_list=[],[]\n",
    "        \n",
    "        for n in range(len(gene_panel['payload']['targets'])):\n",
    "            try:\n",
    "                ensembl_id_list.append(gene_panel['payload']['targets'][n]['type']['data']['id'])\n",
    "                hgnc_list.append(gene_panel['payload']['targets'][n]['type']['data']['name'])\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "        gene_info_df=pd.DataFrame.from_dict({'ENSEMBL_ID':ensembl_id_list,'HGNC_NAME':hgnc_list})\n",
    "        gene_info_df[panel]=True\n",
    "        df_list.append(gene_info_df)\n",
    "\n",
    "    gene_info_merged=pd.concat(df_list,axis=0)\n",
    "    gene_info_merged=gene_info_merged.drop_duplicates('ENSEMBL_ID').reset_index().set_index('HGNC_NAME')\n",
    "    \n",
    "    return gene_info_merged\n",
    "\n",
    "\n",
    "gene_info_merged=extract_ensembl_hgnc_name_df()\n",
    "\n",
    "\n",
    "for panel in ['Panel1','Panel2'][:]:\n",
    "\n",
    "    adata=adata_dict[panel]\n",
    "    adata.var['ENSEMBL_ID']=gene_info_merged.loc[adata.var.index.tolist(),'ENSEMBL_ID'].values\n",
    "    adata.var=adata.var.reset_index().set_index('ENSEMBL_ID',drop=True).rename(columns={'index':'HGNC'})\n",
    "    adata_dict[panel]=adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4d130-daef-43b1-9870-2f8cdbed744d",
   "metadata": {},
   "source": [
    "# BATCH EFFECT CORRECTION WITH SCVI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405de503-55d3-4a1f-afe5-e85f56abccb8",
   "metadata": {},
   "source": [
    "## Run scVI model an both Panel adatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51756ab-e152-4c1c-b7a9-07ad23989b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###====== DEFINE TRAINIG KWARGS\n",
    "\n",
    "train_kwargs = {\n",
    "    \"early_stopping\": True,\n",
    "    \"early_stopping_monitor\": \"elbo_validation\",\n",
    "    \"early_stopping_patience\": 30,\n",
    "    \"early_stopping_min_delta\": 0.01,\n",
    "    \"check_val_every_n_epoch\":1,\n",
    "    \"plan_kwargs\": {\"weight_decay\": 1e-6},\n",
    "    'accelerator':'auto'}\n",
    "\n",
    "search_space={\n",
    "        \"n_hidden\":[128],\n",
    "        \"n_latent\":[10], #20\n",
    "        \"n_layers\": [1], #2\n",
    "        'gene_likelihood':['zinb'],\n",
    "        'max_epochs':[400]}\n",
    "\n",
    "# Create a list of dictionaries where each dictionary represents a set of hyperparameters\n",
    "parameter_combinations = list(itertools.product(*search_space.values()))\n",
    "hyperparameter_sets = [{key: value for key, value in zip(search_space.keys(), combination)} for combination in parameter_combinations]\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "#torch.set_float32_matmul_precision('high')\n",
    "\n",
    "###====== RUN TRAINING\n",
    "for panel in ['Panel1','Panel2']:\n",
    "    print(panel)\n",
    "\n",
    "    adata=adata_dict[panel]\n",
    "\n",
    "    for n,hyperparameters in enumerate(hyperparameter_sets):\n",
    "        loop_time=time.time()\n",
    "    \n",
    "        print_elapsed_time(start,loop_time)\n",
    "        print('set:',str(n+1),'/',str(len(hyperparameter_sets))) \n",
    "        print(hyperparameters)\n",
    "        \n",
    "        ## Create string of the parameters\n",
    "        pairs=[f\"{key}:{value}\" for key, value in hyperparameters.items()]\n",
    "        param_set_string='-'.join(pairs)\n",
    "    \n",
    "        \n",
    "        ## Setup model    \n",
    "        sca.models.SCVI.setup_anndata(adata,\n",
    "                                     layer=\"raw_counts\",\n",
    "                                     #categorical_covariate_keys=['condition'],\n",
    "                                     batch_key='original_sample',\n",
    "                                     #labels_key='free_annotation'\n",
    "                                     )\n",
    "        \n",
    "        vae=sca.models.SCVI(adata,\n",
    "                            n_layers=hyperparameters['n_layers'],\n",
    "                            n_hidden=hyperparameters['n_hidden'],\n",
    "                            n_latent=hyperparameters['n_latent'],\n",
    "                            gene_likelihood=hyperparameters['gene_likelihood']\n",
    "                            )\n",
    "    \n",
    "    \n",
    "        vae.train(max_epochs=hyperparameters['max_epochs'],**train_kwargs)\n",
    "    \n",
    "        ## Plot training results\n",
    "        fig,ax=plt.subplots(1,2,figsize=(9,3))\n",
    "        fig.suptitle('-'.join([panel,param_set_string]))\n",
    "        d=vae.history\n",
    "        ax[0].plot(d['reconstruction_loss_train']['reconstruction_loss_train'], label='reconstruction_loss_train')\n",
    "        ax[0].plot(d['reconstruction_loss_validation']['reconstruction_loss_validation'], label='reconstruction_loss_validation')\n",
    "        ax[1].plot(d['elbo_validation']['elbo_validation'], label='elbo_validation')\n",
    "        ax[1].plot(d['elbo_train']['elbo_train'], label='elbo_train')    \n",
    "        ax[0].legend()\n",
    "        ax[1].legend()\n",
    "    \n",
    "        ## Create string from parameters==> add to the name of the model when saving\n",
    "        pairs=[f\"{key}:{value}\" for key, value in hyperparameters.items()]\n",
    "        param_set_string='-'.join(pairs)\n",
    "        \n",
    "        ## Save model\n",
    "        #path=os.path.join(proc_dir,\"scvi_models\",panel+\"_ts_model_\"+param_set_string)\n",
    "        path=os.path.join(proc_dir,\"scvi_models\",f'{panel}_batch_corr_model_{param_set_string}_data_cells_scale_{scale_param}_asg_conf_{avg_assignment_conf_thr}')\n",
    "        os.makedirs(path, exist_ok=True) \n",
    "        vae.save(path,overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b56741d-37bb-4bca-ac0e-2ec79052d2ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T17:54:12.105701Z",
     "iopub.status.busy": "2024-03-08T17:54:12.105391Z",
     "iopub.status.idle": "2024-03-08T17:54:12.108940Z",
     "shell.execute_reply": "2024-03-08T17:54:12.108557Z",
     "shell.execute_reply.started": "2024-03-08T17:54:12.105686Z"
    }
   },
   "source": [
    "## Load the trained scVI models and latent representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c0e79-c7ae-4479-9497-7cf70b120430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scvi\n",
    "###====== DEFINE HYPERPARAMETERS FOR MODELS TO TRAIN\n",
    "search_space={\n",
    "        \"n_hidden\":[128],\n",
    "        \"n_latent\":[10], #10\n",
    "        \"n_layers\": [1], #1\n",
    "        'gene_likelihood':['zinb'],\n",
    "        'max_epochs':[400]}\n",
    "\n",
    "# Create a list of dictionaries where each dictionary represents a set of hyperparameters\n",
    "parameter_combinations = list(itertools.product(*search_space.values()))\n",
    "hyperparameter_sets = [{key: value for key, value in zip(search_space.keys(), combination)} for combination in parameter_combinations]\n",
    "\n",
    "\n",
    "adata_vae_dict={}\n",
    "\n",
    "for panel in ['Panel1','Panel2'][:]:\n",
    "    adata=adata_dict[panel]\n",
    "\n",
    "    adata_vae_dict[panel]={}\n",
    "    for hyperparameters in hyperparameter_sets:\n",
    "\n",
    "        ## Create string from parameters==> add to the name of the model when saving\n",
    "        pairs=[f\"{key}:{value}\" for key, value in hyperparameters.items()]\n",
    "        param_set_string='-'.join(pairs)\n",
    "        print(panel,param_set_string)\n",
    "        \n",
    "        ## LOAD MODEL\n",
    "        #path=os.path.join(proc_dir,\"scvi_models\",panel+\"_batch_corr_model_\"+param_set_string)\n",
    "        path=os.path.join(proc_dir,\"scvi_models\",f'{panel}_batch_corr_model_{param_set_string}_data_cells_scale_{scale_param}_asg_conf_{avg_assignment_conf_thr}')\n",
    "        try:\n",
    "            vae=scvi.model.SCVI.load(path, adata=adata)\n",
    "        except ValueError:\n",
    "            print(f'Model not found: {param_set_string}\\n')\n",
    "            continue\n",
    "        adata_vae_dict[panel][param_set_string]=vae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce1cef2-ccf0-490c-89eb-2a5d3611dae3",
   "metadata": {},
   "source": [
    "### Check raw UMAP for batch effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc66e9-6bc5-4d1e-9d87-d4719c1371c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for panel in ['Panel1','Panel2']:\n",
    "    print(panel)\n",
    "    adata=adata_dict[panel]\n",
    "    \n",
    "    adata.obsm[\"raw_counts_pca\"]=sc.tl.pca(adata.layers[\"raw_counts\"])\n",
    "    sc.pp.neighbors(adata, n_neighbors=15,use_rep='raw_counts_pca',key_added='raw_counts_neigh',metric='cosine')\n",
    "    sc.tl.umap(adata,n_components=2,neighbors_key='raw_counts_neigh')\n",
    "    \n",
    "    color_cols=['patient','condition','original_sample','sample_region']\n",
    "    adata_dict[panel]=adata\n",
    "    ncols=2\n",
    "    nrows=int(np.ceil(len(color_cols)/ncols))\n",
    "    fig=plt.figure(figsize=(ncols*7,nrows*5))\n",
    "    fig.suptitle(f'{panel}_cells_scale_{scale_param}_asg_conf_{avg_assignment_conf_thr}',fontweight='bold',y=1.02)\n",
    "    \n",
    "    for n,col in enumerate(color_cols):\n",
    "        ax=fig.add_subplot(nrows,ncols,n+1) \n",
    "                \n",
    "        leg_loc='right margin'\n",
    "    \n",
    "        if col in ['fastcluster','leiden_groups']:\n",
    "            leg_loc=\"on data\"\n",
    "        sc.pl.umap(adata, color=col,show=False,ax=ax,size=3,legend_loc=leg_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7261e-3292-4198-be89-1c15346c9f38",
   "metadata": {},
   "source": [
    "## Plot scVI training results + Leiden-cluster batch corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6164c9f-bd51-4463-a6b5-d96ec4acd325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scvi\n",
    "\n",
    "###====== DEFINE TRAINIG KWARGS\n",
    "\n",
    "search_space={\n",
    "        \"n_hidden\":[128],\n",
    "        \"n_latent\":[10], #20\n",
    "        \"n_layers\": [1], #2\n",
    "        'gene_likelihood':['zinb'],\n",
    "        'max_epochs':[400]}\n",
    "\n",
    "# Create a list of dictionaries where each dictionary represents a set of hyperparameters\n",
    "parameter_combinations = list(itertools.product(*search_space.values()))\n",
    "hyperparameter_sets = [{key: value for key, value in zip(search_space.keys(), combination)} for combination in parameter_combinations]\n",
    "\n",
    "\n",
    "import time    \n",
    "start=time.time()\n",
    "\n",
    "for panel in ['Panel1','Panel2']:\n",
    "    print(panel)\n",
    "    #adata_ts_panel=adata_ts_dict[panel]\n",
    "    adata=adata_dict[panel]\n",
    "    \n",
    "    # Print the list of hyperparameter sets\n",
    "    for n,hyperparameters in enumerate(hyperparameter_sets):\n",
    "        ## Create string of the parameters\n",
    "        pairs=[f\"{key}:{value}\" for key, value in hyperparameters.items()]\n",
    "        param_set_string='-'.join(pairs)\n",
    "        \n",
    "        ## Load trained scVI model\n",
    "        vae=adata_vae_dict[panel][param_set_string]\n",
    "\n",
    "\n",
    "        adata.obsm[\"X_scVI_\"+param_set_string]=vae.get_latent_representation()\n",
    "\n",
    "        sc.pp.neighbors(adata, use_rep=\"X_scVI_\"+param_set_string,n_neighbors=15,key_added=\"X_scVI_\"+param_set_string,metric='cosine')\n",
    "        #sc.tl.leiden(adata, key_added='scVI_leiden', resolution=0.6, neighbors_key=\"X_scVI_\"+param_set_string)\n",
    "        sc.tl.umap(adata,n_components=2,neighbors_key=\"X_scVI_\"+param_set_string,random_state=0)\n",
    "        #print('calc done')\n",
    "        \n",
    "        adata_dict[panel]=adata\n",
    "\n",
    "        ## PLOT UMAPS\n",
    "        \n",
    "        color_cols=['patient', 'condition', 'original_sample','sample_region','n_counts', 'n_genes']\n",
    "        ncols=2\n",
    "        nrows=int(np.ceil(len(color_cols)/ncols))\n",
    "        fig=plt.figure(figsize=(ncols*6,nrows*4))\n",
    "\n",
    "        for n,col in enumerate(color_cols):\n",
    "            ax=fig.add_subplot(nrows,ncols,n+1) \n",
    "            fig.suptitle('-'.join([panel,param_set_string,f'\\ncells_scale_{scale_param}_asg_conf_{avg_assignment_conf_thr}']),\n",
    "                         fontweight='bold',fontsize=15,y=0.99)\n",
    "            leg_loc='right margin'\n",
    "\n",
    "            if col in ['fastcluster','scVI_leiden','free_annotation']:\n",
    "                leg_loc=\"on data\"\n",
    "            sc.pl.umap(adata[(adata.obs['n_counts']>0),:], color=col,show=False,ax=ax,size=4,\n",
    "                       vmin='p1',vmax='p99',legend_fontsize=7,legend_loc=leg_loc)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab45a77d-ec89-43d7-a43b-3676e697f225",
   "metadata": {},
   "source": [
    "## Save batch corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88515af1-3822-4830-ba37-7681cf86be61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for panel in [*adata_dict][:]:\n",
    "    adata=adata_dict[panel]\n",
    "\n",
    "    ## Save batch corrected data\n",
    "    fn=os.path.join(proc_dir,f'filtered_batch_corr_{panel}_cells_scale_{scale_param}_asg_conf_{avg_assignment_conf_thr}.h5ad')\n",
    "    adata.write_h5ad(fn,compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa0edd-a731-4b0e-825d-ffcbcdb34e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata.obsm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee0908-8465-423c-9e1c-b37ea99093ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scarches",
   "language": "python",
   "name": "scarches"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
